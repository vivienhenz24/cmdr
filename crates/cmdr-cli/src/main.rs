use clap::{Parser, Subcommand};
use rustyline::error::ReadlineError;
use rustyline::history::DefaultHistory;
use rustyline::Editor;
use std::process;

use cmdr_core::{TranslationEngine, MockInferenceEngine, ShellExecutor, NaturalLanguageRequest};
use cmdr_core::InferenceEngine;
use llm::LlmInstaller;

/// cmdr - A fast, REPL-based command-line interface that translates natural language to shell commands
///
/// Phase 1 CLI Interface Contract:
///
/// Top-level flags (auto-generated by clap):
/// --help, -h     Display help information
/// --version, -V  Display version information
///
/// Phase 1 operational flags:
/// -c, --command <STRING>  Single-shot mode: translate and execute a single natural language command
/// --config <FILE>         Configuration file path (placeholder, not yet used in Phase 1)
///
/// Phase 2+ reserved functionality:
/// - Interactive REPL mode (default when no -c flag provided)
/// - Model selection and configuration options
/// - Inference backend selection (llama.cpp, mistral.rs, etc.)
///
/// Phase 3+ reserved functionality:
/// - Subcommands for advanced operations
/// - Plugin management
/// - History and session management
#[derive(Parser, Debug)]
#[command(
    name = "cmdr",
    version = env!("CMDR_VERSION"),
    author = "cmdr contributors",
    about = "A fast, REPL-based command-line interface that translates natural language to shell commands"
)]
struct Args {
    /// Single-shot mode: translate and execute a single natural language command
    #[arg(short = 'c', long = "command", value_name = "STRING")]
    command: Option<String>,

    /// Configuration file path (placeholder, not yet used)
    #[arg(long = "config", value_name = "FILE")]
    config: Option<String>,

    #[command(subcommand)]
    command_type: Option<Commands>,
}

#[derive(Subcommand, Debug)]
enum Commands {
    /// Install LLM dependencies (Ollama and Llama 3.2 3B)
    Install {
        /// Skip system requirements check
        #[arg(long)]
        skip_checks: bool,
        
        /// Force reinstallation even if already installed
        #[arg(long)]
        force: bool,
    },
    
    /// Check LLM installation status
    Status,
}

fn main() {
    let args = Args::parse();

    // Handle subcommands first
    if let Some(command_type) = args.command_type {
        match command_type {
            Commands::Install { skip_checks, force } => {
                match handle_install_command(skip_checks, force) {
                    Ok(_) => process::exit(0),
                    Err(e) => {
                        eprintln!("Installation error: {}", e);
                        process::exit(1);
                    }
                }
            }
            Commands::Status => {
                match handle_status_command() {
                    Ok(_) => process::exit(0),
                    Err(e) => {
                        eprintln!("Status check error: {}", e);
                        process::exit(1);
                    }
                }
            }
        }
    }

    // Fast-path execution logic for mature UNIX tool behavior

    // Handle -c/--command fast-path
    if let Some(command) = args.command {
        match execute_single_command(&command) {
            Ok(_) => process::exit(0),
            Err(e) => {
                eprintln!("Error: {}", e);
                process::exit(1);
            }
        }
    }

    // Handle --config (placeholder for Phase 2)
    if let Some(config_file) = args.config {
        println!("Configuration file specified: {config_file}");
        // TODO: Implement configuration file parsing in Phase 2
        println!("Configuration loading not yet implemented");
    }

    // Interactive REPL mode
    run_repl();
}

fn execute_single_command(natural_language: &str) -> anyhow::Result<()> {
    let mut inference_engine = MockInferenceEngine::new();
    inference_engine.initialize()?;
    inference_engine.load_model("mock-model")?;
    
    let mut translation_engine = TranslationEngine::new(inference_engine);
    let shell_executor = ShellExecutor::default();
    
    let request = NaturalLanguageRequest {
        text: natural_language.to_string(),
        context: None,
    };
    
    // TODO: Make this async when we have proper async runtime
    let command = tokio::runtime::Runtime::new()?.block_on(
        translation_engine.translate(request)
    )?;
    
    println!("Translated command: {}", command.command);
    
    let result = shell_executor.execute(&command)?;
    if result.success {
        println!("{}", result.output);
    } else {
        eprintln!("Error: {}", result.error.unwrap_or_else(|| "Unknown error".to_string()));
    }
    
    Ok(())
}

fn run_repl() {
    let mut rl = Editor::<(), DefaultHistory>::new().expect("Failed to create line editor");

    loop {
        let readline = rl.readline("[cmdr] ");

        match readline {
            Ok(line) => {
                // Add line to history
                let _ = rl.add_history_entry(line.as_str());

                // Handle non-empty lines
                if !line.trim().is_empty() {
                    println!("(REPL not yet implemented): {line}");
                }
            }
            Err(ReadlineError::Interrupted) => {
                // Ctrl-C: abort current line and continue
                println!();
                continue;
            }
            Err(ReadlineError::Eof) => {
                // Ctrl-D: exit cleanly
                break;
            }
            Err(err) => {
                eprintln!("Error: {err}");
                break;
            }
        }
    }

    // Clean exit
    process::exit(0);
}

fn handle_install_command(skip_checks: bool, force: bool) -> anyhow::Result<()> {
    let mut installer = LlmInstaller::new();
    
    println!("cmdr LLM Installation");
    println!("====================\n");
    
    // Show system information
    if let Ok(system_info) = installer.system_checker().get_system_info() {
        println!("System Information:");
        println!("{}", system_info);
    }
    
    // Check system requirements unless skipped
    if !skip_checks {
        println!("Checking system requirements...");
        if !installer.check_system()? {
            return Err(anyhow::anyhow!("System requirements not met. Use --skip-checks to bypass."));
        }
        println!("‚úì System requirements met\n");
    } else {
        println!("‚ö†Ô∏è  Skipping system requirements check\n");
    }
    
    // Check current status
    let ollama_status = installer.ollama_status()?;
    let model_status = installer.model_status()?;
    
    println!("Current Status:");
    println!("  Ollama: {:?}", ollama_status);
    println!("  Llama 3.2 3B: {:?}\n", model_status);
    
    // Install if needed or forced
    if force || ollama_status == llm::install::InstallStatus::NotInstalled {
        installer.install_ollama()?;
    }
    
    if force || model_status == llm::install::InstallStatus::NotInstalled {
        installer.install_model()?;
    }
    
    println!("üéâ Installation completed successfully!");
    println!("\nYou can now use cmdr with local LLM inference.");
    println!("Try: cmdr -c \"list all files in current directory\"");
    
    Ok(())
}

fn handle_status_command() -> anyhow::Result<()> {
    let installer = LlmInstaller::new();
    
    println!("cmdr LLM Status");
    println!("==============\n");
    
    // Show system information
    if let Ok(system_info) = installer.system_checker().get_system_info() {
        println!("System Information:");
        println!("{}", system_info);
    }
    
    // Check system requirements
    println!("System Requirements:");
    match installer.check_system() {
        Ok(true) => println!("‚úì All requirements met"),
        Ok(false) => println!("‚ùå Some requirements not met"),
        Err(e) => println!("‚ö†Ô∏è  Could not check requirements: {}", e),
    }
    println!();
    
    // Check Ollama status
    println!("Ollama Status:");
    match installer.ollama_status() {
        Ok(status) => {
            match status {
                llm::install::InstallStatus::Installed => {
                    println!("‚úì Ollama is installed");
                    if let Some(path) = installer.ollama_path() {
                        println!("  Path: {}", path.display());
                    }
                    if let Ok(version) = installer.ollama_installer().version() {
                        println!("  Version: {}", version);
                    }
                }
                llm::install::InstallStatus::NotInstalled => {
                    println!("‚ùå Ollama is not installed");
                }
                llm::install::InstallStatus::Installing => {
                    println!("‚è≥ Ollama is currently installing");
                }
                llm::install::InstallStatus::Failed(reason) => {
                    println!("‚ùå Ollama installation failed: {}", reason);
                }
            }
        }
        Err(e) => println!("‚ö†Ô∏è  Could not check Ollama status: {}", e),
    }
    println!();
    
    // Check model status
    println!("Model Status:");
    match installer.model_status() {
        Ok(status) => {
            match status {
                llm::install::InstallStatus::Installed => {
                    println!("‚úì Llama 3.2 3B is installed");
                    println!("  Model: {}", installer.model_name());
                }
                llm::install::InstallStatus::NotInstalled => {
                    println!("‚ùå Llama 3.2 3B is not installed");
                }
                llm::install::InstallStatus::Installing => {
                    println!("‚è≥ Llama 3.2 3B is currently installing");
                }
                llm::install::InstallStatus::Failed(reason) => {
                    println!("‚ùå Llama 3.2 3B installation failed: {}", reason);
                }
            }
        }
        Err(e) => println!("‚ö†Ô∏è  Could not check model status: {}", e),
    }
    
    Ok(())
}
